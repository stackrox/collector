name: Build collector drivers

on:
  workflow_call:
    inputs:
      drivers-bucket:
        type: string
        required: true
        description: The GCP bucket to pull cached drivers from
      bundles-bucket:
        type: string
        required: true
        description: The GCP bucket to pull bundles from
      branch-name:
        type: string
        required: true
        description: Branch CI is running on
    outputs:
      parallel-jobs:
        description: |
          Number of builders used to build drivers, 0 if no driver is built
        value: ${{ jobs.split-tasks.outputs.parallel-jobs }}

env:
  DRIVERS_BUCKET: ${{ inputs.drivers-bucket }}

jobs:
  # This sentinel job exists such that this workflow call "runs" even
  # if subsequent driver build steps are skipped. This means that other
  # workflows can depend on this workflow and still run even if it is skipped
  #
  # This only affects release branches, so is limited to those.
  sentinel:
    runs-on: ubuntu-latest
    if: startsWith(github.ref_name, 'release-') || github.ref_type == 'tag'
    steps:
      - run: echo Drivers Build

  split-tasks:
    runs-on: ubuntu-latest
    if: |
      (github.event_name == 'push' && github.ref_name == 'master') ||
      github.event_name == 'pull_request'
    outputs:
      parallel-jobs: ${{ steps.set-parallel.outputs.parallel-jobs }}
      parallel-array: ${{ steps.set-parallel.outputs.parallel-array }}
    env:
      KERNELS_FILE: ${{ github.workspace }}/kernel-modules/KERNEL_VERSIONS

    steps:
      - uses: actions/checkout@v4

      - name: Patch files
        env:
          BUILD_LEGACY_DRIVERS: ${{ contains(github.event.pull_request.labels.*.name, 'build-legacy-probes') || github.event_name == 'push' }}
          OSCI_RUN: 1
          DOCKERIZED: 1
          CHECKOUT_BEFORE_PATCHING: false

        run: |
          git fetch

          # Initialize just the falco submodule
          git submodule update --init ${{ github.workspace }}/falcosecurity-libs

          ${{ github.workspace }}/kernel-modules/build/patch-files.sh \
            ${{ inputs.branch-name }} \
            "${BUILD_LEGACY_DRIVERS}" \
            ${{ github.workspace }} \
            kernel-modules/build/prepare-src \
            /tmp

      - name: Authenticate with GCP
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS_COLLECTOR_SVC_ACCT }}'

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'

      - name: Create a mock cache
        if: ${{ !contains(github.event.pull_request.labels.*.name, 'no-cache') }}
        run: |
          ${{ github.workspace }}/kernel-modules/build/mock-cache.sh

      - name: Get build tasks
        env:
          USE_KERNELS_FILE: true
          DOCKERIZED: 1
          OUTPUT_DIR: /tmp
          CACHE_DIR: /tmp
          BLOCKLIST_DIR: ${{ github.workspace }}/kernel-modules
          SCRIPTS_DIR: ${{ github.workspace }}/kernel-modules/build

        run: |
          ${{ github.workspace }}/kernel-modules/build/get-build-tasks.sh

          mkdir -p /tmp/tasks
          mv /tmp/build-tasks /tmp/tasks/all

      - name: Set number of parallel builds
        id: set-parallel
        shell: python
        run : |
          import json
          import math
          import os

          kernels = set()

          with open('/tmp/tasks/all', 'r') as tasks:
            for line in tasks.readlines():
              kernel = line.split()[0]
              kernels.add(kernel)

          # Add a parallel job every 10 kernels, capped to 32
          parallel_jobs = math.ceil(len(kernels)/10)
          if parallel_jobs > 32:
            parallel_jobs=32

          parallel = [a for a in range(parallel_jobs)]

          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write(f'parallel-jobs={parallel_jobs}\n')
            f.write(f'parallel-array={json.dumps(parallel)}\n')

      - name: Split kernels
        env:
          TASKS_DIR: /tmp/tasks
          DRIVER_BUILDERS: ${{ steps.set-parallel.outputs.parallel-jobs }}

        run: |
          ${{ github.workspace }}/kernel-modules/build/kernel-splitter.py

      - name: Store tasks and sources
        uses: actions/upload-artifact@v4
        with:
          name: tasks-and-sources
          if-no-files-found: ignore
          path: |
            /tmp/kobuild-tmp/versions-src/
            /tmp/tasks/**/**/all
          retention-days: 7

  build-drivers:
    runs-on: ubuntu-latest
    needs:
      - split-tasks
    if: ${{ needs.split-tasks.outputs.parallel-jobs > 0 }}
    env:
      BUILDERS_DIR: ${{ github.workspace }}/kernel-modules/build

    strategy:
      matrix:
        builder: ${{ fromJSON(needs.split-tasks.outputs.parallel-array) }}

    steps:
      - uses: actions/checkout@v4

      - name: Authenticate with GCP
        uses: 'google-github-actions/auth@v2'
        with:
          credentials_json: '${{ secrets.GOOGLE_CREDENTIALS_COLLECTOR_SVC_ACCT }}'

      - name: 'Set up Cloud SDK'
        uses: 'google-github-actions/setup-gcloud@v2'

      - name: Restore tasks and sources
        uses: actions/download-artifact@v4
        with:
          name: tasks-and-sources
          path: /tmp

      - name: Set required builders
        id: required-builders
        run: |
          builders=()

          for builder_file in "${BUILDERS_DIR}/"*.Dockerfile; do
            builder="${builder_file%".Dockerfile"}"
            builder="${builder#"${BUILDERS_DIR}/"}"

            if [[ ! -f  "/tmp/tasks/${builder}/${{ matrix.builder }}/all" ]]; then
              continue
            fi

            tasks="$(wc -l < "/tmp/tasks/${builder}/${{ matrix.builder }}/all")"

            if ((tasks)); then
              builders+=("${builder}")
            fi
          done

          echo "builders=${builders[*]}" >> "$GITHUB_OUTPUT"

      - name: Build builders
        if: ${{ steps.required-builders.outputs.builders != '' }}
        run: |
          # SC gets confused here, this for loop gets expanded to the
          # builders and runs once for each of the needed ones
          # shellcheck disable=SC2043
          for builder in ${{ steps.required-builders.outputs.builders }}; do
            docker build --tag "${builder}:latest" \
              -f "${BUILDERS_DIR}/${builder}.Dockerfile" \
              ${{ github.workspace }}/kernel-modules/build/
          done

      - name: Build drivers
        if: ${{ steps.required-builders.outputs.builders != '' }}
        run: |
          mkdir -p /tmp/{output,bundles,FAILURES}

          # this is required for GHA to upload a build failures artifact when
          # no build fails
          touch /tmp/FAILURES/.dummy

          # SC gets confused here, this for loop gets expanded to the
          # builders and runs once for each of the needed ones
          # shellcheck disable=SC2043
          for builder in ${{ steps.required-builders.outputs.builders }}; do
            # Download bundles for current builder
            awk '{ print "gs://${{ inputs.bundles-bucket }}/bundle-"$1".tgz" }' "/tmp/tasks/${builder}/${{ matrix.builder }}/all" |
              sort | uniq | gsutil -m cp -I /tmp/bundles

            docker run --rm -i \
              -v /tmp/tasks:/tasks:ro \
              -v /tmp/kobuild-tmp/versions-src:/kobuild-tmp/versions-src \
              -v /tmp/output:/kernel-modules \
              -v /tmp/bundles:/bundles:ro \
              -v /tmp/FAILURES:/FAILURES \
              -e DOCKERIZED=1 \
              --name "${builder}" \
              "${builder}:latest" < "/tmp/tasks/${builder}/${{ matrix.builder }}/all"

            rm -rf /tmp/bundles/*
          done

      - name: Store built drivers
        uses: actions/upload-artifact@v4
        with:
          name: built-drivers-${{ matrix.builder }}
          path: /tmp/output
          if-no-files-found: ignore
          retention-days: 1

      - name: Store build failures
        uses: actions/upload-artifact@v4
        with:
          name: driver-build-failures-${{ matrix.builder }}
          path: /tmp/FAILURES
          if-no-files-found: ignore
          retention-days: 1
