diff --git a/bpf/filler_helpers.h b/bpf/filler_helpers.h
index e37cea8..1a15376 100644
--- a/bpf/filler_helpers.h
+++ b/bpf/filler_helpers.h
@@ -493,8 +493,11 @@ static __always_inline u16 bpf_pack_addr(struct filler_data *data,
 		res = bpf_probe_read_str(&data->buf[(data->state->tail_ctx.curoff + 1) & SCRATCH_SIZE_HALF],
 					 UNIX_PATH_MAX,
 					 usrsockaddr_un->sun_path);
-
-		size += res;
+		if (res <= 0) {
+			size = 0;
+		} else {
+			size += res;
+		}
 
 		break;
 	default:
@@ -703,8 +706,11 @@ static __always_inline long bpf_fd_to_socktuple(struct filler_data *data,
 		int res = bpf_probe_read_str(&data->buf[(data->state->tail_ctx.curoff + 1 + 8 + 8) & SCRATCH_SIZE_HALF],
 					     UNIX_PATH_MAX,
 					     us_name);
-
-		size += res;
+		if (res <= 0) {
+			size = 0;
+		} else {
+			size += res;
+		}
 
 		break;
 	}
@@ -745,7 +751,7 @@ static __always_inline int __bpf_val_to_ring(struct filler_data *data,
 			res = bpf_probe_read_str(&data->buf[data->state->tail_ctx.curoff & SCRATCH_SIZE_HALF],
 						 PPM_MAX_ARG_SIZE,
 						 (const void *)val);
-			if (res < 0)
+			if (res <= 0)
 				return PPM_FAILURE_INVALID_USER_MEMORY;
 			len = res;
 		} else {
diff --git a/bpf/fillers.h b/bpf/fillers.h
index 2458b09..3a7d8b1 100644
--- a/bpf/fillers.h
+++ b/bpf/fillers.h
@@ -1451,7 +1451,8 @@ static __always_inline pid_t bpf_task_tgid_vnr(struct task_struct *task)
 	return bpf_pid_vnr(bpf_task_tgid(task));
 }
 
-#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
+#elif LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0) && \
+    ( !defined(RHEL_RELEASE_CODE) || RHEL_RELEASE_CODE < RHEL_RELEASE_VERSION(8,1) )
 
 static __always_inline pid_t bpf_task_pid_nr_ns(struct task_struct *task,
 						enum pid_type type,
@@ -1521,6 +1522,7 @@ static __always_inline pid_t bpf_task_tgid_vnr(struct task_struct *task)
 #endif /* LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0) */
 
 #define MAX_CGROUP_PATHS 6
+#define MAX_CGROUP_PATHS_READ 5
 
 static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 					       int subsys_id,
@@ -1544,7 +1546,7 @@ static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 	int res = bpf_probe_read_str(&buf[off & SCRATCH_SIZE_HALF],
 				     SCRATCH_SIZE_HALF,
 				     subsys_name);
-	if (res < 0)
+	if (res <= 0)
 		return PPM_FAILURE_INVALID_USER_MEMORY;
 
 	off += res - 1;
@@ -1572,8 +1574,8 @@ static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 		}
 	}
 
-	#pragma unroll MAX_CGROUP_PATHS
-	for (int k = MAX_CGROUP_PATHS - 1; k >= 0 ; --k) {
+	#pragma unroll MAX_CGROUP_PATHS_READ
+	for (int k = MAX_CGROUP_PATHS_READ - 1; k >= 0 ; --k) {
 		if (!cgroup_path[k])
 			continue;
 
@@ -1591,7 +1593,7 @@ static __always_inline int __bpf_append_cgroup(struct css_set *cgroups,
 		res = bpf_probe_read_str(&buf[off & SCRATCH_SIZE_HALF],
 						SCRATCH_SIZE_HALF,
 						cgroup_path[k]);
-		if (res < 0)
+		if (res <= 0)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		if (res > 1) {
@@ -1629,8 +1631,7 @@ do {											\
 
 static __always_inline int bpf_append_cgroup(struct task_struct *task,
 					     char *buf,
-					     int *len)
-{
+					     int *len) {
 	struct css_set *cgroups = _READ(task->cgroups);
 	int res;
 
@@ -1640,9 +1641,9 @@ static __always_inline int bpf_append_cgroup(struct task_struct *task,
 
 #if IS_ENABLED(CONFIG_CGROUP_SCHED)
 #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 15, 0)
-	APPEND_CGROUP(cpu);
+    APPEND_CGROUP(cpu);
 #else
-	APPEND_CGROUP(cpu_cgroup);
+    APPEND_CGROUP(cpu_cgroup);
 #endif
 #endif
 
@@ -1694,7 +1695,7 @@ static __always_inline int bpf_accumulate_argv_or_env(struct filler_data *data,
 			return PPM_FAILURE_BUFFER_FULL;
 
 		len = bpf_probe_read_str(&data->buf[off & SCRATCH_SIZE_HALF], SCRATCH_SIZE_HALF, arg);
-		if (len < 0)
+		if (len <= 0)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		*args_len += len;
@@ -1796,7 +1797,7 @@ FILLER(proc_startupdate, true)
 						SCRATCH_SIZE_HALF,
 						&data->buf[data->state->tail_ctx.curoff & SCRATCH_SIZE_HALF]);
 
-		if (exe_len < 0)
+		if (exe_len <= 0)
 			return PPM_FAILURE_INVALID_USER_MEMORY;
 
 		/*
@@ -1938,13 +1939,12 @@ FILLER(proc_startupdate, true)
 	return PPM_FAILURE_BUG;
 }
 
-FILLER(proc_startupdate_2, true)
-{
+FILLER(proc_startupdate_2, true) {
 	struct task_struct *task;
 	int cgroups_len = 0;
 	int res;
 
-	task = (struct task_struct *)bpf_get_current_task();
+	task = (struct task_struct *) bpf_get_current_task();
 
 	/*
 	 * cgroups
@@ -1953,7 +1953,7 @@ FILLER(proc_startupdate_2, true)
 	if (res != PPM_SUCCESS)
 		return res;
 
-	res = __bpf_val_to_ring(data, (unsigned long)data->tmp_scratch, cgroups_len, PT_BYTEBUF, -1, false);
+	res = __bpf_val_to_ring(data, (unsigned long) data->tmp_scratch, cgroups_len, PT_BYTEBUF, -1, false);
 	if (res != PPM_SUCCESS)
 		return res;
 
diff --git a/bpf/quirks.h b/bpf/quirks.h
index a26bfd9..410b0fe 100644
--- a/bpf/quirks.h
+++ b/bpf/quirks.h
@@ -40,6 +40,8 @@ or GPL2.txt for full copies of the license.
 #define BPF_SUPPORTS_RAW_TRACEPOINTS
 #endif
 
+#define RHEL_RELEASE_VERSION(X,Y) 0
+
 #endif /* RHEL_RELEASE_CODE */
 /* Redefine asm_volatile_goto to work around clang not supporting it
  */
diff --git a/ppm_cputime.c b/ppm_cputime.c
index 5e7c7e6..71563b0 100644
--- a/ppm_cputime.c
+++ b/ppm_cputime.c
@@ -231,7 +231,7 @@ static void cputime_advance(cputime_t *counter, cputime_t new)
  * runtime accounting.
  */
 static void cputime_adjust(struct task_cputime *curr,
-#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0))
+#if (LINUX_VERSION_CODE >= KERNEL_VERSION(4, 3, 0)) || (PPM_RHEL_RELEASE_CODE > 0 && PPM_RHEL_RELEASE_CODE >= PPM_RHEL_RELEASE_VERSION(7, 6))
 			   struct prev_cputime *prev,
 #else
 			   struct cputime *prev,
diff --git a/ppm_events.c b/ppm_events.c
index 6c321f6..7e498e3 100644
--- a/ppm_events.c
+++ b/ppm_events.c
@@ -24,7 +24,7 @@ or GPL2.txt for full copies of the license.
 #include <linux/version.h>
 #include <linux/module.h>
 #include <linux/kernel.h>
-#include <asm/mman.h>
+#include <linux/mman.h>
 #include <linux/in.h>
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(2, 6, 20)
 #include <linux/mount.h>
